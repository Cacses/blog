{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/039_nlp_transfer/nlp_transfer.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de texto - Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el [post](https://sensioai.com/blog/038_clasificacion_texto) anterior vimos cómo podemos entrenar una `red neuronal recurrente` para clasificar texto. En este tipo de tarea, nuestro modelo será capaz de asignar una etiqueta concreta entre varias a una pieza de texto determinada. Vimos, por ejemplo, que podemos saber de manera automática si una opinión de una película es positiva o negativa. En este post vamos a resolver exactamente el mismo caso, pero introduciendo una nueva técnica muy utilizada: el `transfer learning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta técnica nos permite entrenar redes neuronales de manera más rápida, con menores requisitos computacionales y permitiendo el entrenamiento de redes con mejores prestaciones con pequeños datasets. La idea consiste en entrenar una red neuronal en un gran dataset, con grandes recursos computacionales, y una vez entrenada utilizar el conocimiento que este modelo ya posee como punto de partida para nuestro caso particular en el proceso conocido como `fine tuning`.\n",
    "\n",
    "![](https://pennylane.ai/qml/_images/transfer_learning_general.png)\n",
    "\n",
    "Este proceso de `fine tuning` puede variar según la tarea, pero lo más común es sustituir las capas finales de la red por nuevas capas adaptadas a nuestra tarea y entrenar solo estas nuevas capas, dejando intactas las capas ya entrenadas. Sin embargo, en el caso en el que los datos usados en la nueva tarea sean muy diferentes que los usados originalmente, también es común el entrenamiento de toda la red, a partir de los pesos pre-entrenados. \n",
    "\n",
    "Como comentábamos al principio, esta técnica es muy utilizada en la práctica. Podemos encontrar modelos pre-entrenados en diferentes librerías, que podemos descargar y empezar a utilizar directamente. El `transfer learning` es utilizado tanto en aplicaciones de lenguaje como tareas visuales, y lo usaremos de manera extensiva de ahora en adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## El *dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimos utilizando el dataset IMDB, disponible en [torchtext](https://pytorch.org/text/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:05:50.098816Z",
     "start_time": "2020-09-02T17:05:49.536511Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:49.385453Z",
     "start_time": "2020-09-02T17:05:50.099802Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sensio\\miniconda3\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\sensio\\miniconda3\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\sensio\\miniconda3\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "TEXT = torchtext.data.Field(tokenize = 'spacy')\n",
    "LABEL = torchtext.data.LabelField(dtype = torch.long)\n",
    "\n",
    "train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:49.401523Z",
     "start_time": "2020-09-02T17:06:49.386457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:49.416536Z",
     "start_time": "2020-09-02T17:06:49.402524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy', '.', 'It', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life', ',', 'such', 'as', '\"', 'Teachers', '\"', '.', 'My', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'Bromwell', 'High', \"'s\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"', 'Teachers', '\"', '.', 'The', 'scramble', 'to', 'survive', 'financially', ',', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', 'teachers', \"'\", 'pomp', ',', 'the', 'pettiness', 'of', 'the', 'whole', 'situation', ',', 'all', 'remind', 'me', 'of', 'the', 'schools', 'I', 'knew', 'and', 'their', 'students', '.', 'When', 'I', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school', ',', 'I', 'immediately', 'recalled', '.........', 'at', '..........', 'High', '.', 'A', 'classic', 'line', ':', 'INSPECTOR', ':', 'I', \"'m\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers', '.', 'STUDENT', ':', 'Welcome', 'to', 'Bromwell', 'High', '.', 'I', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'Bromwell', 'High', 'is', 'far', 'fetched', '.', 'What', 'a', 'pity', 'that', 'it', 'is', \"n't\", '!'], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Embeddings* pre-entrenados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer ejemplo de `transfer learning` que vamos a ver es el uso de `embeddings` pre-entrenados. Recuerda que un embedding es la respresentación vectorial de cada palabra en el vocabulario que utilizaremos para alimentar nuestra red recurrente. Puedes aprender más sobre `embeddings` en este [post](https://sensioai.com/blog/037_charRNN). En `torchtext` podemos descargar estos `embeddings` en la función `build_vocab`, con el parámtero `vectors`. En la documentación encontrarás los diferentes `embeddings` disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:51.179497Z",
     "start_time": "2020-09-02T17:06:49.417539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10002, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 10000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\", # embeddings pre-entrenados\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "len(TEXT.vocab), len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y, de la misma manera que hicimos en el post anterior, definimos nuestros *dataloaders* con la clase `torchtext.data.BucketIterator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:51.225297Z",
     "start_time": "2020-09-02T17:06:51.181498Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sensio\\miniconda3\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "dataloader = {\n",
    "    'train': torchtext.data.BucketIterator(train_data, batch_size=64, shuffle=True, sort_within_batch=True, device=device),\n",
    "    'test': torchtext.data.BucketIterator(test_data, batch_size=64, device=device)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos exactamente el mismo modelo que ya vimos en el post anterior. Este modelo está compuesto, principalmente, por la capa `embedding`, que en este caso sustituiremos por los vectores descargados anteriormente, y las capas recurrente y lineal, que entrenaremos desde cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:51.240470Z",
     "start_time": "2020-09-02T17:06:51.226301Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim=128, hidden_dim=128, output_dim=2, num_layers=2, dropout=0.2, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = torch.nn.GRU(\n",
    "            input_size=embedding_dim, \n",
    "            hidden_size=hidden_dim, \n",
    "            num_layers=num_layers, \n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(2*hidden_dim if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # no entrenamos los embeddings\n",
    "        with torch.no_grad():\n",
    "            #text = [sent len, batch size]        \n",
    "            embedded = self.embedding(text)        \n",
    "        #embedded = [sent len, batch size, emb dim]        \n",
    "        output, hidden = self.rnn(embedded)        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        y = self.fc(output[-1,:,:].squeeze(0))     \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez definido el modelo, sustituimos los tensores en la capa `embedding` por los vectores pre-entrenados descargados anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:51.474095Z",
     "start_time": "2020-09-02T17:06:51.242472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(input_dim=len(TEXT.vocab), bidirectional=True, embedding_dim=100)\n",
    "\n",
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "# ponemos a cero los pesos correspondientes a los tokens <unk> y <pad>\n",
    "model.embedding.weight.data[TEXT.vocab.stoi[TEXT.unk_token]] = torch.zeros(100)\n",
    "model.embedding.weight.data[TEXT.vocab.stoi[TEXT.pad_token]] = torch.zeros(100)\n",
    "\n",
    "outputs = model(torch.randint(0, len(TEXT.vocab), (100, 64)))\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar nuestra red usamos el bucle estándar que ya usamos en posts anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:51.489416Z",
     "start_time": "2020-09-02T17:06:51.476095Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def fit(model, dataloader, epochs=5):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_loss, train_acc = [], []\n",
    "        bar = tqdm(dataloader['train'])\n",
    "        for batch in bar:\n",
    "            X, y = batch\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(X)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
    "            train_acc.append(acc)\n",
    "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
    "        bar = tqdm(dataloader['test'])\n",
    "        val_loss, val_acc = [], []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in bar:\n",
    "                X, y = batch\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_hat = model(X)\n",
    "                loss = criterion(y_hat, y)\n",
    "                val_loss.append(loss.item())\n",
    "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
    "                val_acc.append(acc)\n",
    "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
    "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-02T17:01:41.410Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                     | 0/391 [00:00<?, ?it/s]C:\\Users\\sensio\\miniconda3\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "loss 0.60367 acc 0.65394: 100%|█████████████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 15.83it/s]\n",
      "val_loss 0.70378 val_acc 0.54723: 100%|█████████████████████████████████████████████████████████| 391/391 [00:21<00:00, 18.33it/s]\n",
      "loss 0.41899 acc 0.78906:   1%|▎                                                                  | 2/391 [00:00<00:22, 17.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 loss 0.60367 val_loss 0.70378 acc 0.65394 val_acc 0.54723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.38105 acc 0.83003: 100%|█████████████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 16.26it/s]\n",
      "val_loss 0.62558 val_acc 0.70619: 100%|█████████████████████████████████████████████████████████| 391/391 [00:20<00:00, 18.74it/s]\n",
      "loss 0.27767 acc 0.84375:   1%|▎                                                                  | 2/391 [00:00<00:23, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 loss 0.38105 val_loss 0.62558 acc 0.83003 val_acc 0.70619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.30007 acc 0.87230: 100%|█████████████████████████████████████████████████████████████████| 391/391 [00:23<00:00, 16.30it/s]\n",
      "val_loss 0.34502 val_acc 0.84991: 100%|█████████████████████████████████████████████████████████| 391/391 [00:21<00:00, 18.55it/s]\n",
      "loss 0.22283 acc 0.89844:   1%|▎                                                                  | 2/391 [00:00<00:30, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 loss 0.30007 val_loss 0.34502 acc 0.87230 val_acc 0.84991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.26492 acc 0.89062: 100%|█████████████████████████████████████████████████████████████████| 391/391 [00:23<00:00, 16.34it/s]\n",
      "val_loss 0.30862 val_acc 0.86378: 100%|█████████████████████████████████████████████████████████| 391/391 [00:20<00:00, 18.71it/s]\n",
      "loss 0.35504 acc 0.82812:   1%|▎                                                                  | 2/391 [00:00<00:24, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 loss 0.26492 val_loss 0.30862 acc 0.89062 val_acc 0.86378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.22634 acc 0.90991: 100%|█████████████████████████████████████████████████████████████████| 391/391 [00:23<00:00, 16.39it/s]\n",
      "val_loss 0.30647 val_acc 0.86997:  74%|██████████████████████████████████████████▍              | 291/391 [00:15<00:05, 19.33it/s]"
     ]
    }
   ],
   "source": [
    "fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez nuestro modelo ha sido entrenado, podemos generar predicciones exactamente igual que hicimos en el post anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T16:36:23.366252Z",
     "start_time": "2020-09-01T16:36:22.942250Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict(model, X):\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        X = torch.tensor(X).to(device)\n",
    "        pred = model(X)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T16:36:23.382248Z",
     "start_time": "2020-09-01T16:36:23.367255Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sensio\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"this film is terrible\", \"this film is great\", \"this film is good\", \"a waste of time\"]\n",
    "tokenized = [[tok.text for tok in nlp.tokenizer(sentence)] for sentence in sentences]\n",
    "indexed = [[TEXT.vocab.stoi[_t] for _t in t] for t in tokenized]\n",
    "tensor = torch.tensor(indexed).permute(1,0)\n",
    "predictions = torch.argmax(predict(model, tensor), axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como has visto en el ejemplo anterior, utilizar unos `embeddings` pre-entrenados puede darnos mucho mejores resultados que entrenarlos desde cero, ya que la representación de nuestras palabras será mucho mejor desde el principio. Siguiendo en esta línea, podemos sustituir nuestra capa `embedding` por otro modelo que nos aportará todavía mejores resultados, un `transformer`. \n",
    "\n",
    "Estos modelos aparecieron alrededor de 2017, y fueron presentados en el famoso artículo [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf). Desde su aparación, estos modelos están batiendo todos los *benchmarks* en las diferentes tareas de procesado de lenguaje, y son utilizados como base de cualquier modelo competente a día de hoy. De momento, no entraremos en detalles en la definición de esta arquitectura (lo dejamos para un futuro post, ya que hay mucha tela que cortar) pero vamos a ver como utilizar un `transformer` para hacer `transfer learning` y obtener muy buenos resultados de manera rápida. \n",
    "\n",
    "Una librería muy utilizada para trabajar con estos modelos es la librería `transformers` de [huggingface](https://huggingface.co/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:53.519427Z",
     "start_time": "2020-09-02T17:06:51.491415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sensio\\miniconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from transformers) (4.48.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: joblib in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from requests->transformers) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\sensio\\miniconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, tendremos que utilizar el mismo `tokenizer` utilizado para entrenar el modelo original. En este caso usaremos la red conocida como `BERT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:55.976181Z",
     "start_time": "2020-09-02T17:06:53.520429Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:55.992130Z",
     "start_time": "2020-09-02T17:06:55.977181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'world', 'how', 'are', 'you', '?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize('Hello WORLD how ARE yoU?')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:06:56.007534Z",
     "start_time": "2020-09-02T17:06:55.993130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7592, 2088, 2129, 2024, 2017, 1029]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia de las `redes neuronales recurrentes`, los transformers trabajan con longitudes de secuencia fijas (no son modelos recurrentes). Es por este motivo que tenemos que asegurarnos que ninguna frase en el dataset tiene mayor longitud que la máxima permitida por `BERT`, que es de 512 palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:07:03.793315Z",
     "start_time": "2020-09-02T17:07:03.779499Z"
    }
   },
   "outputs": [],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "\n",
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchtext` nos da la libertad de definir nuestros propios tokenizers, y podemos incluirlos de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:22:18.054844Z",
     "start_time": "2020-09-02T17:22:18.039843Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "\n",
    "LABEL = torchtext.data.LabelField(dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:25:34.082483Z",
     "start_time": "2020-09-02T17:22:18.056843Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = torchtext.datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "dataloader = {\n",
    "    'train': torchtext.data.BucketIterator(train_data, batch_size=64, shuffle=True, sort_within_batch=True, device=device),\n",
    "    'test': torchtext.data.BucketIterator(test_data, batch_size=64, device=device)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos los datos preparados con el nuevo tokenizer, necesitamos definir nuestro nuevo modelo. En este caso, `BERT` se encargará de actuar como nuestra capa `embedding`, proveyendo de la mejor representación posible de nuestro texto para que las siguientes capas puedan clasificarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T17:25:34.099485Z",
     "start_time": "2020-09-02T17:25:34.083484Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class BERT(torch.nn.Module):\n",
    "    def __init__(self, bert, hidden_dim=256, output_dim=2, n_layers=2, bidirectional=True, dropout=0.2):\n",
    "        super().__init__()        \n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')        \n",
    "        \n",
    "        # freeze BERT\n",
    "        for name, param in self.bert.named_parameters():                \n",
    "            if name.startswith('bert'):\n",
    "                param.requires_grad = False\n",
    "\n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        self.rnn = torch.nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):                       \n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text)[0]\n",
    "        output, hidden = self.rnn(embedded)        \n",
    "        y = self.fc(output[:,-1,:].squeeze(1))     \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-02T17:19:06.120Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss 0.40127 acc 0.81412:  57%|████████████████████████████████████▉                            | 222/391 [03:59<03:14,  1.15s/it]"
     ]
    }
   ],
   "source": [
    "model = BERT(bert)\n",
    "fit(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y finalmente, podemos generar las predicciones de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    tokenized = [tok[:max_input_length-2] for tok in tokenizer.tokenize(sentence)]\n",
    "    indexed = [tokenizer.cls_token_id] + tokenizer.convert_tokens_to_ids(tokenized) + [tokenizer.sep_token_id]\n",
    "    tensor = torch.tensor([indexed]).to(device)\n",
    "    model.net.eval()\n",
    "    return torch.sigmoid(model.net(tensor)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hola"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "233.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
